# -*- coding: utf-8 -*-
"""
Created on Tue Apr  7 14:01:35 2020

@author: alizadeh
"""

def  generateTimeSeries(batchSize, nSteps):
    """
    This function generates a number (batchSize) times series, each such series
    is represented by a sequence of numbers. The length  of the sequences are
    all equal to nSteps. 
    
    These time series are generated by the the formula
        0.5* sin((t-o1)*(10*f1)+10) + 0.2*sin((t-o2)*(20*f2+20)) + noise
    
    The numbers o1, o2,f1,f2 are generated randomely between 0 and 1.
    The noise is a uniform random number between 0 and 0.1

    """
    import numpy as np
    import matplotlib.pyplot as plt
    
    freq1,freq2,offset1, offset2=np.random.rand(4, batchSize,1)
    time=np.linspace(0,1,nSteps)
    series=0.5*np.sin((time-offset1)*(freq1*10+10))
    series+=0.2*np.sin((time-offset2)*(freq2*20+20))
    series+=0.1*np.random.rand(batchSize,nSteps)  
    #plt.plot(series)
    #plt.show()
    return series[...,np.newaxis].astype(np.float32)

nSteps=50 #length of each series
series=generateTimeSeries(10000, nSteps+1)# 10000 differentseries are generated
# Separate training, validation and test sets
XTrain,yTrain=series[:7000,:nSteps],series[:7000,-1]
XValid,yValid=series[7000:9000,:nSteps],series[7000:9000,-1]
XTest,yTest=series[9000:,:nSteps],series[9000:,-1]

from tensorflow.keras import losses
import numpy as np

# plot some of the time series generated:

import matplotlib.pyplot as plt

for i in range(10):
    plt.plot(series[i,:,])
    plt.show()
    

from tensorflow.keras.layers import Input, Flatten, Dense, SimpleRNN
from tensorflow.keras.models import Model

################The Naive Method: Just predic the last item in the series

yPred=XValid[:,-1]

testError0=np.mean(losses.mean_squared_error(yValid,yPred))
print('error for last number heuristics:',testError0)

if input('continue to linear regression method? Y/N')=='n':
    import sys
    sys.exit()
################Using linear regression
inputLayer1=Input(shape=XTrain[0,:,:].shape)
tmp=Flatten()(inputLayer1)
model1=Model(inputLayer1,Dense(1)(tmp))
model1.compile(optimizer='rmsprop',loss='mse')
model1.summary()
history1=model1.fit(XTrain, yTrain,epochs=20,validation_data=(XValid,yValid))

testError1=model1.evaluate(XTest,yTest)
print('Test Error on linear regression:', testError1)

if input('continue to one-layer RNN method? Y/N')=='n':
    import sys
    sys.exit()
################# Using Simple RNN
inputLayer2=Input(shape=[None,1])

model2=Model(inputLayer2,SimpleRNN(1)(inputLayer2))
model2.compile(optimizer='rmsprop',loss='mse')
model2.summary()
history2=model2.fit(XTrain, yTrain,epochs=20,validation_data=(XValid,yValid))

testError2=model2.evaluate(XTest,yTest)
print('Test Error on SimpleRNN regression:', testError2)

if input('continue to deep RNN method? Y/N')=='n':
    import sys
    sys.exit()
################# Using deep Simple RNN
inputLayer3=Input(shape=[None,1])
tmp=SimpleRNN(20,return_sequences=True)(inputLayer3)
tmp=SimpleRNN(20,return_sequences=True)(tmp)

model3=Model(inputLayer3,SimpleRNN(1)(tmp))
model3.compile(optimizer='rmsprop',loss='mse')
model3.summary()
history3=model3.fit(XTrain, yTrain,epochs=20,validation_data=(XValid,yValid))

testError3=model3.evaluate(XTest,yTest)
print('Test Error on SimpleRNN regression:', testError3)

if input('continue to Regression method with multiple prediction? Y/N')=='n':
    import sys
    sys.exit()
    
################# Using Regression with multiple predictions
    ###############BUGGY
stepsAhead=10
series4=generateTimeSeries(10000, nSteps+stepsAhead)
XTrain4,yTrain4=series4[:7000,:nSteps],series4[:7000,-stepsAhead:,0]
XValid4,yValid4=series4[7000:9000,:nSteps],series4[7000:9000,-stepsAhead:,0]
XTest4,yTest4=series4[9000:,:nSteps],series4[9000:,-stepsAhead:,0]

inputLayer4=Input(shape=XTrain4[0,:,:].shape)
tmp=Flatten()(inputLayer4)
model4=Model(inputLayer4,Dense(stepsAhead)(tmp))
model4.compile(optimizer='rmsprop',loss='mse')
model4.summary()
history4=model4.fit(XTrain4, yTrain4,epochs=20,validation_data=(XValid4,yValid4))

testError4=model4.evaluate(XTest4,yTest4)
print('Test Error on SimpleRNN regression:', testError4)

if input('continue to deep RNN method with multiple prediction? Y/N')=='n':
    import sys
    sys.exit()
    
################# Using deep Simple RNN with multiple predictions
    ##################BUGGY###################
stepsAhead=10
series5=generateTimeSeries(10000, nSteps+stepsAhead)
XTrain5=series5[:7000,:nSteps]
XValid5=series5[7000:9000,:nSteps]
XTest5=series5[9000:,:nSteps]
yTrain5=np.empty((10000,nSteps,stepsAhead))
for s in range(1,stepsAhead+1):
    yTrain5[:,:,s-1]=series5[:,s:s+nSteps,0]
yValid5=yTrain5[7000:9000]
yTest5=yTrain5[9000:]
yTrain5=yTrain5[:7000]

from tensorflow.keras.layers import TimeDistributed
inputLayer5=Input(shape=[None,1])
tmp=SimpleRNN(20,return_sequences=True)(inputLayer5)
tmp=SimpleRNN(20,return_sequences=True)(tmp)
outputLayer5=TimeDistributed(Dense(10))(tmp)
model5=Model(inputLayer5,outputLayer5)
model5.compile(optimizer='rmsprop',loss='mse')
model5.summary()
history5=model5.fit(XTrain5, yTrain5,epochs=20,validation_data=(XValid5,yValid5))

testError5=model5.evaluate(XTest5,yTest5)
print('Test Error on SimpleRNN regression:', testError5)

#if input('continue to deep RNN method with multiple prediction? Y/N')=='n':
#    import sys
#    sys.exit()
    
    
    
print('Naive error\t\t', testError0)
print('Regression error\t', testError1)
print('Single RNN error\t', testError2)
print('Deep RNN error\t\t', testError3)
print('Regression 10 steps error\t', testError4)
print('Deep RNN 10 steps error\t', testError5)

 